{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a252e43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import requests\n",
    "import random\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToolNode : Its function is to listen for tool calls from the LLM and then automatically call the tool and return the result back into the graph.\n",
    "#ToolCondition: Inbuilt function of langgraph , it is a pre built conditional edge that helps in deciding the flow of the graph meaning wheter the flow goes to tool node next or back to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b43dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "search_tool = DuckDuckGoSearchRun(region=\"us-en\")\n",
    "\n",
    "@tool\n",
    "def calculator(first_num: float, second_num: float, operation: str) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a basic arithmetic operation on two numbers.\n",
    "    Supported operations: add, sub, mul, div\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if operation == \"add\":\n",
    "            result = first_num + second_num\n",
    "        elif operation == \"sub\":\n",
    "            result = first_num - second_num\n",
    "        elif operation == \"mul\":\n",
    "            result = first_num * second_num\n",
    "        elif operation == \"div\":\n",
    "            if second_num == 0:\n",
    "                return {\"error\": \"Division by zero is not allowed\"}\n",
    "            result = first_num / second_num\n",
    "        else:\n",
    "            return {\"error\": f\"Unsupported operation '{operation}'\"}\n",
    "        \n",
    "        return {\"first_num\": first_num, \"second_num\": second_num, \"operation\": operation, \"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch latest stock price for a given symbol (e.g. 'AAPL', 'TSLA') \n",
    "    using Alpha Vantage with API key in the URL.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={symbol}&apikey=C9PE94QUEW9VWGFM\"\n",
    "    r = requests.get(url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1f9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759760773.949360   51518 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of Apple (AAPL) is 258.02.\n"
     ]
    }
   ],
   "source": [
    "# Make tool list\n",
    "tools = [get_stock_price, search_tool, calculator]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    ")\n",
    "# Make the LLM tool-aware\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "# state\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "# graph nodes\n",
    "def chat_node(state: ChatState):\n",
    "    \"\"\"LLM node that may answer or request a tool call.\"\"\"\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "# graph structure\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "\n",
    "# If the LLM asked for a tool, go to ToolNode; else finish\n",
    "graph.add_conditional_edges(\"chat_node\", tools_condition)\n",
    "\n",
    "graph.add_edge(\"tools\", \"chat_node\")\n",
    "chatbot = graph.compile()\n",
    "\n",
    "out = chatbot.invoke({\"messages\": [HumanMessage(content=\"what is the price of apple!\")]})\n",
    "\n",
    "print(out[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc1e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".agenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
